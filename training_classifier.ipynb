{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792\n",
      "8968\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "data_file = './training_data.p'\n",
    "with open(data_file, mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    car_image_names = data['car_image_names']\n",
    "    not_car_image_names = data['not_car_image_names']\n",
    "\n",
    "print(len(car_image_names))\n",
    "print(len(not_car_image_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from lesson_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.33 Seconds to extract features...\n"
     ]
    }
   ],
   "source": [
    "color_space = 'HLS' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "spatial_size = (16, 16)\n",
    "hist_bins = 32\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = 'ALL'\n",
    "spatial_feat = True\n",
    "hist_feat = True\n",
    "hog_feat = True\n",
    "\n",
    "t=time.time()\n",
    "car_features = extract_features(car_image_names, color_space=color_space, spatial_size=spatial_size,\n",
    "                                hist_bins=hist_bins, orient=orient,\n",
    "                                pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                                spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(not_car_image_names, color_space=color_space, spatial_size=spatial_size,\n",
    "                                hist_bins=hist_bins, orient=orient,\n",
    "                                pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                                spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract features...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split 80% 20% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 9 orientations 8 pixels per cell and 2 cells per block\n",
      "Feature vector length: 6156\n"
     ]
    }
   ],
   "source": [
    "# Split up data into randomized training and test sets\n",
    "scaled_X, y = shuffle(scaled_X, y)\n",
    "\n",
    "rand_state = np.random.randint(0, 100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell, 'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed features to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle_file = './processed_features.p'\n",
    "#\n",
    "#try:\n",
    "#    with open(pickle_file, 'wb') as pfile:\n",
    "#        pickle.dump(\n",
    "#            {\n",
    "#                'X_train': X_train,\n",
    "#                'y_train': y_train,\n",
    "#                'X_test': X_test,\n",
    "#                'y_test': y_test\n",
    "#            },\n",
    "#            pfile, pickle.HIGHEST_PROTOCOL)\n",
    "#except Exception as e:\n",
    "#    print('Unable to save data to', pickle_file, ':', e)\n",
    "#    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = {'C':[0.001, 0.005, 0.01]}\n",
    "\n",
    "#svr = LinearSVC()\n",
    "\n",
    "# Use smaller sample size as GridSearchCV() takes a long time\n",
    "#sample_size = 1000\n",
    "\n",
    "#X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "#t=time.time()\n",
    "#clf = GridSearchCV(svr, parameters)\n",
    "#clf.fit(X_train[0:sample_size], y_train[0:sample_size])\n",
    "#t2 = time.time()\n",
    "\n",
    "#print(round(t2-t, 2), 'Seconds to tune parameters...')\n",
    "#print('Best parameters are: ', clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't seem to get this function to produce sensible result. Using default C=1 to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with processed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.37 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9885\n",
      "My SVC predicts:      [ 1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.\n",
      "  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.\n",
      "  1.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  1.  1.  0.  1.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  0.  1.\n",
      "  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.  1.\n",
      "  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.]\n",
      "For these 100 labels:  [ 1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.\n",
      "  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.\n",
      "  1.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  1.  1.  0.  1.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  0.  1.\n",
      "  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.  1.\n",
      "  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.]\n",
      "0.007 Seconds to predict 100 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "\n",
    "n_predict = 100\n",
    "print('My SVC predicts:     ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save classifier to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = './svc_pickle.p'\n",
    "\n",
    "try:\n",
    "    with open(pickle_file, 'wb') as pfile:\n",
    "        pickle.dump(\n",
    "            {\n",
    "                'svc': svc,\n",
    "                'X_scaler': X_scaler,\n",
    "                'orient': orient,\n",
    "                'pix_per_cell': pix_per_cell,\n",
    "                'cell_per_block': cell_per_block,\n",
    "                'spatial_size': spatial_size,\n",
    "                'hist_bins': hist_bins,\n",
    "                'color_space': color_space,\n",
    "                'hog_channel': hog_channel,\n",
    "                'spatial_feat': spatial_feat,\n",
    "                'hist_feat': hist_feat,\n",
    "                'hog_feat': hog_feat\n",
    "            },\n",
    "            pfile, pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
