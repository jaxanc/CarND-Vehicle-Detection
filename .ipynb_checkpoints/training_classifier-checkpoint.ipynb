{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792\n",
      "8968\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "data_file = './training_data.p'\n",
    "with open(data_file, mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    car_image_names = data['car_image_names']\n",
    "    not_car_image_names = data['not_car_image_names']\n",
    "\n",
    "print(len(car_image_names))\n",
    "print(len(not_car_image_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "\n",
    "def color_hist(img, nbins=32):    #bins_range=(0, 256)\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9,\n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = plt.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)\n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel],\n",
    "                                        orient, pix_per_cell, cell_per_block,\n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)\n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient,\n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.62 Seconds to extract features...\n"
     ]
    }
   ],
   "source": [
    "color_space = 'HLS' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "spatial_size = (16, 16)\n",
    "hist_bins = 32\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = 'ALL'\n",
    "spatial_feat = True\n",
    "hist_feat = True\n",
    "hog_feat = True\n",
    "\n",
    "t=time.time()\n",
    "car_features = extract_features(car_image_names, color_space=color_space, spatial_size=spatial_size,\n",
    "                                hist_bins=hist_bins, orient=orient,\n",
    "                                pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                                spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(not_car_image_names, color_space=color_space, spatial_size=spatial_size,\n",
    "                                hist_bins=hist_bins, orient=orient,\n",
    "                                pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                                spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract features...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split 80% 20% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 8 orientations 8 pixels per cell and 3 cells per block\n",
      "Feature vector length: 8640\n"
     ]
    }
   ],
   "source": [
    "# Split up data into randomized training and test sets\n",
    "scaled_X, y = shuffle(scaled_X, y)\n",
    "\n",
    "rand_state = np.random.randint(0, 100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell, 'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed features to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle_file = './processed_features.p'\n",
    "#\n",
    "#try:\n",
    "#    with open(pickle_file, 'wb') as pfile:\n",
    "#        pickle.dump(\n",
    "#            {\n",
    "#                'X_train': X_train,\n",
    "#                'y_train': y_train,\n",
    "#                'X_test': X_test,\n",
    "#                'y_test': y_test\n",
    "#            },\n",
    "#            pfile, pickle.HIGHEST_PROTOCOL)\n",
    "#except Exception as e:\n",
    "#    print('Unable to save data to', pickle_file, ':', e)\n",
    "#    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.99 Seconds to tune parameters...\n",
      "Best parameters are:  {'C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#parameters = {'C':[0.001, 0.005, 0.01]}\n",
    "\n",
    "#svr = LinearSVC()\n",
    "\n",
    "# Use smaller sample size as GridSearchCV() takes a long time\n",
    "#sample_size = 1000\n",
    "\n",
    "#X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "#t=time.time()\n",
    "#clf = GridSearchCV(svr, parameters)\n",
    "#clf.fit(X_train[0:sample_size], y_train[0:sample_size])\n",
    "#t2 = time.time()\n",
    "\n",
    "#print(round(t2-t, 2), 'Seconds to tune parameters...')\n",
    "#print('Best parameters are: ', clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't seem to get this function to produce sensible result. Using default C=1 to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with processed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.65 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.989\n",
      "My SVC predicts:      [ 0.  1.  1.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.\n",
      "  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.\n",
      "  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.\n",
      "  1.  1.  1.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.\n",
      "  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.\n",
      "  1.  1.  0.  0.  1.  1.  0.  1.  1.  1.]\n",
      "For these 100 labels:  [ 0.  1.  1.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.\n",
      "  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.\n",
      "  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.\n",
      "  1.  1.  1.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.\n",
      "  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.\n",
      "  1.  1.  0.  0.  1.  1.  0.  1.  1.  1.]\n",
      "0.007 Seconds to predict 100 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "\n",
    "n_predict = 100\n",
    "print('My SVC predicts:     ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save classifier to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = './svc_pickle.p'\n",
    "\n",
    "try:\n",
    "    with open(pickle_file, 'wb') as pfile:\n",
    "        pickle.dump(\n",
    "            {\n",
    "                'svc': svc,\n",
    "                'X_scaler': X_scaler,\n",
    "                'orient': orient,\n",
    "                'pix_per_cell': pix_per_cell,\n",
    "                'cell_per_block': cell_per_block,\n",
    "                'spatial_size': spatial_size,\n",
    "                'hist_bins': hist_bins,\n",
    "                'color_space': color_space,\n",
    "                'hog_channel': hog_channel,\n",
    "                'spatial_feat': spatial_feat,\n",
    "                'hist_feat': hist_feat,\n",
    "                'hog_feat': hog_feat\n",
    "            },\n",
    "            pfile, pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
